---
title: "ST694 Project"
author: "Douglas Bowen"
date: '2022-03-31'
output: html_document
---

```{r, include=FALSE, echo=FALSE, message=FALSE}
#Setup Chunk
knitr::opts_chunk$set(echo = TRUE,tidy.opts=list(width.cutoff=80),tidy=TRUE)

#Required Libraries for Course
library(ISLR2)
library(class)
library(boot)
library(glmnet) #Added A2/A3
library(pls) #Added A2/A3
library(splines) #Added A3
library(leaps)#Added A3
library(gam) #Added A3
#remove.packages(c("tree","randomForest"))
#install.packages(c("tree","randomForest"))
library(tree) #Added A4
library(randomForest) #Added A4

#Optional Libraries Not Recommended By Course
#Libraries for Graphing
library(tidyverse)
library(scales)

#Other Useful Libraries (for R Markdown)
library(knitr)
library(kableExtra)
library(latex2exp)
library(formatR)

#Old Packages from Prior Courses
library(multcomp)
library(multcompView)
library(pander)
library(MASS)
library(tinytex)


#install.packages(c("ISLR2","class","boot","tidyverse","scales","knitr","kableExtra","latex2exp","multcomp","multcompview","pander","MASS","gridExtra","leaps","bestglm","corrplot"))

#Notes:
#Use "install.packages('library_name_here')" then use "library(library_name_here)"
```

# Loading Data

```{r, include=FALSE, echo=FALSE, message=FALSE}

#test <- read.csv("test.csv")
train <- read.csv("Data/train.csv")

#Remove ID Column (Useless)
train$Id = NULL

#Begin by examining NA values
Tot_NA <- sum(is.na(train))/prod(dim(train)) #Total NA Values

Col_NA <- sort(colMeans(is.na(train)), decreasing=TRUE) #Column NA Values
kable(Col_NA[which(Col_NA>0)], caption="Column NA Rates", col.names = c("NA Percentage")) #Column NA Values > 0%

#Remove NA Columns > Threshold
threshold_na = 0.4
Col_Remove = names(Col_NA[which(Col_NA>threshold_na)])
Col_Impute = names(Col_NA[which(Col_NA<=threshold_na & Col_NA>0)])

#Generating Subset of Data
#test <- test[,which(!names(test) %in% Col_Remove)]
train <- train[,which(!names(train) %in% Col_Remove)]

#Mode Imputation Function
getmode <- function(v) {
   uniqv <- unique(v[!is.na(v)])
   uniqv[which.max(tabulate(match(v, uniqv)))]
}

#Fill in Remaining NA Data - Use Mean Method since Large Dataset
#Examine Data
for (column in Col_Impute){
  col_dat = train[,column]
  hist(col_dat, main=column, sub=class(col_dat))
  
  if (class(col_dat) == "numeric"){
      train[is.na(col_dat),column] = mean(col_dat, na.rm=TRUE)
      
  } else if (class(col_dat) == "integer"){
      train[is.na(col_dat),column] = getmode(col_dat)
      
  } else{
      print("Not Accounted For Yet")
  }
}

#Examine Correlation Matrix for Colinearity Prior to Analysis (maybe move above)
threshold_corr = 0.7
corr_check <- cor(train[,which(!sapply(train, class) %in% "character")], use = "complete.obs")
corr_check <- as.matrix(corr_check)
corr_check[upper.tri(corr_check)] <- 0

corr_total <- length(corr_check[corr_check>threshold_corr & corr_check != 1])
corr_pairs <- rep(NA, corr_total)
cnt=1

for (i in 1:nrow(corr_check)){
  for (j in 1:ncol(corr_check)){
    if (corr_check[i,j]>threshold_corr & corr_check[i,j] != 1){
      rownames(corr_check)[i]
      colnames(corr_check)[j]
      corr_pairs[cnt] <- paste(rownames(corr_check)[i], ":",colnames(corr_check)[j], sep="")
      cnt=cnt+1
    }
  }
}

corr_pairs <- str_split_fixed(corr_pairs,":",2)
corr_remove <- unique(corr_pairs[,1])

#Remove One of Two Highly Co-linear Terms
train <- train[,which(!names(train) %in% corr_remove)]



#Or, can utilize PCA to deal with this instead. --> No, actually good to remove multicolinearity in advance of PCA
#can give PCA unfair wieghting
# including the nearly-redundant variables can cause the PCA to overemphasize their contribution
#https://stats.stackexchange.com/questions/50537/should-one-remove-highly-correlated-variables-before-doing-pca




#Temporary Assumption
train["Response"] <- ifelse(train["Response"] < 7, 0, 1)



#Export to Cleaned Train CSV Set
train_y = subset(train, select=c(Response))
train_x = subset(train, select=-c(Response))

write.csv(train,"Data/train_clean.csv", row.names = FALSE)
write.csv(train_y,"Data/train_y_clean.csv", row.names = FALSE)
write.csv(train_x,"Data/train_x_clean.csv", row.names = FALSE)

```





















